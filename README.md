# Knowledge Nexus

## 1. Project Overview (Application Description)
- **Project Name:** Knowledge Nexus
- **Main Purpose:** Knowledge Nexus is a multi-agent AI application designed to provide users with thoroughly researched, verified, and professionally presented knowledge on any given topic. It leverages automated internet research (via Google Custom Search), AI-driven content synthesis (using Azure/OpenAI LLMs), and a robust Human-in-the-Loop (HITL) verification process. The system stores knowledge efficiently in a vector database (ChromaDB with Azure OpenAI Embeddings) and can operate in a simulated mode for key functions if external API keys are unavailable.
- **Problem Solved:** Addresses the need for reliable and trustworthy knowledge in an age of information overload and misinformation, combining AI efficiency with human oversight.

## 2. Features
- **Automated Internet Research:** Utilizes Google Custom Search API to gather information from the web. Falls back to simulated search data if API keys are not configured.
- **Vector-based Knowledge Storage:** Employs ChromaDB with embeddings generated by Azure OpenAI Embedding services to store and retrieve textual information efficiently. Requires specific Azure embedding API keys.
- **LLM-Powered Content Synthesis:** Leverages Large Language Models (Azure OpenAI preferred, fallback to Standard OpenAI) to synthesize coherent summaries and insights from verified data. Operates with simulated LLM responses if API keys are missing or invalid.
- **Human-in-the-Loop (HITL) Data Verification:** Incorporates a process for human users to review, verify, or correct flagged data points, pausing and resuming the workflow accordingly.
- **Customizable Document Generation:** Generates final knowledge documents from synthesized content, potentially using LLMs for formatting.
- **Degraded Mode Operation:** Key components like internet search and LLM synthesis can function using simulated data if their respective API keys (Google Search, OpenAI/Azure) are not provided, allowing for development and testing in restricted environments.
- **Modular Multi-Agent Architecture:** Built using LangGraph, allowing for flexible and extensible research workflows.

## 3. System Architecture
- Briefly describe the multi-component architecture: Frontend (React), Backend (Python with FastAPI & LangGraph), Database (ChromaDB).
- **Architecture Diagram:**
  ```
  +-------------------+      HTTP/WebSocket     +-----------------------------+
  |     Frontend      | <---------------------> |           Backend           |
  |    (React App)    |                         | (FastAPI + LangGraph Agents)|
  +-------------------+                         +-----------------------------+
          ^                                                 |
          | API Calls (Data, Commands)                      | Vector Embeddings,
          |                                                 | Storage & Retrieval
          |                                                 v
          +-------------------------------------------> +----------------------+
                                                        |       ChromaDB       |
                                                        | (Vector Database)    |
                                                        +----------------------+
  ```
- **Technology Stack Summary:** React, FastAPI, LangGraph, ChromaDB, Google Search API, Azure/OpenAI LLMs & Embedding APIs.

## 4. Project Structure
```
.
├── backend/
│   ├── agents/
│   ├── models/
│   ├── services/
│   ├── main.py
│   ├── requirements.txt
│   └── .env.example
├── frontend/
│   ├── public/
│   ├── src/
│   ├── package.json
│   └── .env.example
├── design/
│   ├── technical/
│   │   └── detailed_design.md
│   └── ...
├── chroma_db_store/
└── README.md
```
### Key Directory Descriptions:

*   **`./` (Repository Root):**
    *   This is the main container for the entire project. The primary active directories are `backend/` and `frontend/`, alongside design documents and other project-level files.

*   **`backend/` (Top-Level Directory):**
    *   Houses the Python-based backend application.
    *   **`main.py`**: The entry point for the FastAPI application.
    *   **`agents/`**: Contains definitions and logic for the LangGraph agents (e.g., Researcher, Verifier, Synthesizer).
    *   **`models/`**: Pydantic models for data validation and serialization (API request/response schemas).
    *   **`services/`**: Modules for integrating with external services, such as the ChromaDB client (`chroma_service.py`) and LLM integrations.
    *   **`requirements.txt`**: Lists the Python dependencies for the backend.
    *   **`.env.example`**: An example file for environment variables. Copy this to `.env` for your local setup.

*   **`frontend/` (Top-Level Directory):**
    *   Contains the React-based frontend application.
    *   **`src/`**: The primary folder for React components, pages, services, and other JavaScript/JSX code.
    *   **`public/`**: Stores static assets like `index.html`, favicons, and images.
    *   **`package.json`**: Defines frontend project metadata, dependencies (managed by npm), and scripts (like `start`, `build`).
    *   **`.env.example`**: An example file for frontend environment variables.

*   **`design/` (Top-Level Directory):**
    *   Stores all project design and planning documents.
    *   **`technical/detailed_design.md`**: The comprehensive technical design document for the project.

*   **`chroma_db_store/` (Top-Level Directory):**
    *   This directory is the default location where ChromaDB persists its vector database files when configured for local storage. The exact path is configured in `backend/services/chroma_service.py`. It's crucial for maintaining the knowledge base between application restarts. This directory will be created automatically by ChromaDB if it doesn't exist when data is first persisted.

(Note: An older directory named `knowledge_nexus/` also exists at the root; it contains outdated or redundant code and should be ignored.)


## 5. Development Environment Setup

### 5.1. Prerequisites
- Python (3.9 or newer recommended)
- Node.js (Latest LTS version recommended) & npm
- Git

### 5.2. Backend Setup (`backend/`)

1.  **Navigate to Backend Directory:**
    ```bash
    cd backend
    ```
2.  **Create and Activate Virtual Environment:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate  # On macOS/Linux
    # venv\Scripts\activate  # On Windows
    ```
3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
4.  **Configure Environment Variables:**
    - Copy `backend/.env.example` to `backend/.env`:
      ```bash
      cp .env.example .env
      ```
    - **Edit `backend/.env` and provide your API keys and settings:**
      ```env
      # Google Custom Search API
      GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY"
      GOOGLE_CSE_ID="YOUR_GOOGLE_CSE_ID"

      # Azure OpenAI for Language Models (Primary LLM)
      AZURE_OPENAI_API_KEY="YOUR_AZURE_OPENAI_API_KEY"
      AZURE_OPENAI_ENDPOINT="https://YOUR_AZURE_RESOURCE.openai.azure.com/"
      OPENAI_API_VERSION="2023-07-01-preview" # Or your specific API version
      AZURE_OPENAI_DEPLOYMENT_NAME="YOUR_LLM_DEPLOYMENT_NAME" # e.g., gpt-35-turbo, gpt-4

      # Standard OpenAI API (Fallback LLM, if Azure is not used or fails)
      # OPENAI_API_KEY="YOUR_OPENAI_API_KEY" # Uncomment and set if using

      # Azure OpenAI for Embeddings (ChromaDB)
      # Note: AZURE_OPENAI_ENDPOINT and OPENAI_API_VERSION are often reused from LLM config
      AZURE_OPENAI_EMBEDDING_API_KEY="YOUR_AZURE_EMBEDDING_API_KEY" # Often same as AZURE_OPENAI_API_KEY but can be different
      AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME="YOUR_EMBEDDING_MODEL_DEPLOYMENT_NAME" # e.g., text-embedding-ada-002

      # Legacy/Optional - Tavily API Key (currently not the primary search tool)
      # TAVILY_API_KEY="YOUR_TAVILY_API_KEY"
      ```
    - **Explanation of Keys:**
        - `GOOGLE_API_KEY` & `GOOGLE_CSE_ID`: For internet research via Google Custom Search. If missing, simulated search data is used.
        - `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT`, `OPENAI_API_VERSION`, `AZURE_OPENAI_DEPLOYMENT_NAME`: For using Azure OpenAI as the primary LLM for synthesis and document generation.
        - `OPENAI_API_KEY`: For using standard OpenAI API as a fallback if Azure is not configured. If both Azure and Standard OpenAI are unconfigured, LLM operations use simulated responses.
        - `AZURE_OPENAI_EMBEDDING_API_KEY`, `AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME`: Required by `ChromaService` to generate embeddings for storing data in ChromaDB. If missing, `ChromaService` initialization will fail. `AZURE_OPENAI_ENDPOINT` and `OPENAI_API_VERSION` from the LLM section are also used by the embedding service.
    - Ensure `.env` is in `.gitignore`.

### 5.3. Frontend Setup (`frontend/`)

1.  **Navigate to Frontend Directory:**
    ```bash
    cd frontend
    ```
2.  **Install Dependencies:**
    ```bash
    npm install
    ```
3.  **Configure Environment Variables (if needed):**
    - Create `frontend/.env` from `frontend/.env.example` if it exists, or create it manually.
    - The primary variable is:
      ```env
      REACT_APP_API_BASE_URL=http://localhost:8000
      ```
    - This tells the React app where the backend API is running.

## 6. How to Run Locally

To run Knowledge Nexus, both the backend and frontend servers must be running simultaneously, typically in separate terminal sessions.

1.  **Start the Backend Server:**
    - Navigate to `backend/`.
    - Activate the Python virtual environment: `source venv/bin/activate`.
    - Run:
      ```bash
      uvicorn main:app --reload --host 0.0.0.0 --port 8000
      ```
    - The backend API will be available at `http://localhost:8000`. Check console output for LLM and ChromaService status.

2.  **Start the Frontend Development Server:**
    - Navigate to `frontend/`.
    - Run:
      ```bash
      npm start
      ```
    - The frontend application will typically open automatically in your browser at `http://localhost:3000`.

- Once both are running, access the application at `http://localhost:3000`.

## 7. Deployment

Deploying Knowledge Nexus involves setting up the backend service and the frontend application.

### 7.1. Backend Deployment
- **Package:** Ensure all dependencies from `requirements.txt` are installed in your deployment environment.
- **Environment Variables:** All API keys and configuration variables specified in `backend/.env` (see Backend Setup) **must** be set as environment variables in your deployment environment (e.g., via CI/CD variables, PaaS configuration, or Docker environment variables).
- **ASGI Server:** Run the FastAPI application using a production-grade ASGI server like Uvicorn with Gunicorn workers. Example:
  ```bash
  gunicorn -k uvicorn.workers.UvicornWorker backend.main:app -w 4 --bind 0.0.0.0:8000
  ```
  Adjust worker count (`-w 4`) based on your server resources.
- **ChromaDB Data:** The `chroma_db_store/` directory (or the path configured for `ChromaService`) needs to be persistent if you want to retain the knowledge base across deployments or restarts. Consider using a mounted volume in containerized deployments.

### 7.2. Frontend Deployment
- **Build Static Assets:** In the `frontend/` directory, run:
  ```bash
  npm run build
  ```
  This creates an optimized static build of the React application in `frontend/build/`.
- **Serve Static Files:** Deploy the contents of the `frontend/build/` directory using a static web server (e.g., Nginx, Apache) or a cloud object storage service with static website hosting features (e.g., AWS S3, Azure Blob Storage, Google Cloud Storage).
- **API Configuration:** Ensure the `REACT_APP_API_BASE_URL` environment variable was correctly set at build time, or configure a reverse proxy (e.g., in Nginx) to route API requests from the same domain as the frontend to the backend service.

## 8. Contributing
We welcome contributions to Knowledge Nexus! Please follow these general guidelines:
- Fork the repository.
- Create a new branch for your feature or bug fix.
- Ensure your code adheres to existing style guidelines.
- Write clear and concise commit messages.
- Test your changes thoroughly.
- Submit a pull request with a detailed description of your changes.

## 9. License
This project is licensed under the MIT License. See the LICENSE file for details (if a LICENSE file is present).
